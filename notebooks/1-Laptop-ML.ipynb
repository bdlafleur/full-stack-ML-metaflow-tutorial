{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767f5035-57e9-4125-959f-0697b11803a3",
   "metadata": {},
   "source": [
    "# Creating flows from your laptop machine learning code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b212fe-0a93-4b21-a651-2e12f717e899",
   "metadata": {},
   "source": [
    "To introduce data scientists to [Metaflow](https://docs.metaflow.org/), it will be key to show them how they can take their pre-existing ML code and turn it into flows. Arguably, the 3 most practical types of models are\n",
    "\n",
    "* Random forests\n",
    "* Boosted trees, and\n",
    "* Neural nets.\n",
    "\n",
    "To this end, in what follows, we show how you would take code for each of these types of models and turn it into a Metaflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806bcaa-a0b7-455e-b84a-d0518f16fa9c",
   "metadata": {},
   "source": [
    "## Setup instructions\n",
    "\n",
    "_Note:_ Include setup instructions in README. Also perhaps include them here, depending on whether you include command line stuff later.\n",
    "\n",
    "We'll be using `conda` to install the necessary packages but you can also use `pip` or `virtualenv`. To use `conda`, install the Anaconda distribution from [here](https://www.anaconda.com/products/individual).\n",
    "Using the command line, execute\n",
    "\n",
    "```bash\n",
    "conda env create -f env.yml\n",
    "```\n",
    "to create your environment. You can then activate it by executing\n",
    "\n",
    "```bash\n",
    "conda activate full-stack-metaflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17ccec6-9378-45ce-ac82-ed294592c1ef",
   "metadata": {},
   "source": [
    "## Your Laptop Machine Learning Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53389bf1-0106-4720-958f-bb24f3f7de29",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9925b-c119-47d2-8689-1d4bb91a3e50",
   "metadata": {},
   "source": [
    "This is typical random forest code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9decbcc8-ef14-4081-863e-766ea206052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2350ee1d-4cfe-4a62-a0c1-5ccb2c37d606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "[0.96666667 0.96666667 0.9        0.93333333 1.        ]\n",
      "[0.96666667 0.96666667 0.93333333 0.9        1.        ]\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,\n",
    "    random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4636c5c-511f-4de1-9218-45d8578019d3",
   "metadata": {},
   "source": [
    "### Boosted trees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49546aba-ded5-421f-a8b7-21827a995371",
   "metadata": {},
   "source": [
    "This is typical boosted tree code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04f5ea0-db93-4589-97ee-86f23da1a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:14:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0.28583017 0.9239239  0.28583017 ... 0.9239239  0.05169873 0.9239239 ]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# read in data\n",
    "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../data/agaricus.txt.test')\n",
    "# specify parameters via map|\n",
    "param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82c397-d206-440f-a85e-ebc8a53fbe87",
   "metadata": {},
   "source": [
    "### Neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed7261-7263-44a0-af9a-cbb54533869e",
   "metadata": {},
   "source": [
    "This is (somewhat) typical deep learning code (we're using Keras & TensorFlow but you can use PyTorch, fast.ai, JAX, and/or PyTorch Lightning, among others <-- check if all of this is true, HBA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2718e0ab-b848-4a0d-af38-2d1e9fc0672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/vision/mnist_convnet/\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aace2c3e-7dbb-492a-9fc6-bfb71bdd05f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906402cf-8a86-4506-80a8-a10f0edb0d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 18:14:11.542968: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b376cd-62a5-420e-947a-babfa55d1261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 18:14:14.544811: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "422/422 [==============================] - 12s 27ms/step - loss: 0.7205 - accuracy: 0.7823 - val_loss: 0.0841 - val_accuracy: 0.9775\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.1300 - accuracy: 0.9619 - val_loss: 0.0623 - val_accuracy: 0.9825\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0885 - accuracy: 0.9725 - val_loss: 0.0460 - val_accuracy: 0.9868\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0757 - accuracy: 0.9757 - val_loss: 0.0436 - val_accuracy: 0.9877\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 11s 27ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.0384 - val_accuracy: 0.9888\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0540 - accuracy: 0.9838 - val_loss: 0.0354 - val_accuracy: 0.9905\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 0.0325 - val_accuracy: 0.9898\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 11s 27ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.0314 - val_accuracy: 0.9920\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0467 - accuracy: 0.9847 - val_loss: 0.0287 - val_accuracy: 0.9918\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0300 - val_accuracy: 0.9918\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 0.0325 - val_accuracy: 0.9913\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 0.0271 - val_accuracy: 0.9932\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0260 - val_accuracy: 0.9923\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 11s 25ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.0266 - val_accuracy: 0.9920\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 11s 26ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0274 - val_accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf900ff100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fba1ae3-8e0d-498a-9b6a-1e232b00fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026157839223742485\n",
      "Test accuracy: 0.9912999868392944\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42fd0b-4540-41f3-993a-7a6a32798c97",
   "metadata": {},
   "source": [
    "In the next lesson, we'll take these machine learning scripts and turn them into (meta)flows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:full-stack-metaflow]",
   "language": "python",
   "name": "conda-env-full-stack-metaflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
